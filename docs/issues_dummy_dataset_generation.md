# 더미 데이터셋 생성 이슈 정리

---

## 전체 요약

초기 더미 데이터셋은 파이프라인 연결과 화면 검증에는 충분했지만, 모델 성능 검증 용도로는 난이도가 낮아 평가 결과가 과대해지는 문제가 있었습니다.  
특히 `02_risk_prediction` 단계에서 Logistic Regression이 반복적으로 `1.0` 성능을 기록해, 모델의 일반화 성능이 아니라 데이터 생성 규칙의 단순성이 측정되는 상태였습니다.

핵심 쟁점은 "위험군 라벨이 feature에서 너무 쉽게 역산되는 구조"였습니다. 따라서 단순 노이즈 추가만으로는 충분하지 않았고, 분포 겹침 강화, 모순 케이스 확대, 라벨 생성 독립성 확보, 검증 방식 개선을 함께 다뤄야 했습니다.

---

## 문제 정의

1. 모델 평가 지표가 비정상적으로 높아 모델 비교/선정의 의미가 약해졌습니다.
2. 위험군/정상군 분포가 지나치게 분리되어 실제 교육 데이터의 복잡성을 반영하지 못했습니다.
3. 단일 train/test 분할 기반 평가는 표본 변동성에 취약해 실험 결과 신뢰도가 낮았습니다.
4. 중간/기말 시점이 다른 컬럼 구조를 가질 때 결측 처리와 후속 모델링 전략이 불명확했습니다.
5. 데이터셋 품질 이슈가 모델 이슈처럼 보이면서 진단 우선순위가 혼재되었습니다.

---

## 원인 파악

1. 클래스 분리가 과도했습니다.

- 위험군과 정상군의 점수/행동 변수 구간이 겹치지 않아 선형 분류기로도 쉽게 분리되었습니다.

2. 현실적 경계 사례가 부족했습니다.

- 낮은 점수지만 참여도가 높은 학생.
- 높은 점수지만 결석이 많은 학생.
- 지필과 수행 점수가 상반되는 학생.
- 실제 학교 데이터에 흔한 이런 패턴이 충분히 포함되지 않았습니다.

3. 라벨 생성 결합도가 높았습니다.

- feature 생성과 `at_risk` 생성이 동일 잠재요인에 강하게 연결되어 라벨 예측이 과도하게 쉬웠습니다.
- 결과적으로 모델이 학습해야 할 불확실성이 거의 존재하지 않았습니다.

4. 검증 체계가 약했습니다.

- 표본 수가 작고 단일 분할 의존도가 높아 실험 간 변동성과 과대평가 가능성을 충분히 통제하지 못했습니다.

5. 시점 표현 전략이 불완전했습니다.

- 중간 시점에서 `final_score = NaN`은 타당했지만, 이를 어떻게 모델링에 반영할지(결측 플래그, 대체 정책)가 일관되게 정의되지 않았습니다.

---

## 해결 방안

1. 데이터 분포 겹침을 의도적으로 확대했습니다.

- 점수/행동 변수에 노이즈를 주입해 단순 선형 분리 난이도를 높였습니다.
- 클래스 경계 부근 샘플 비중을 높여 모델 판별 난이도를 현실화했습니다.

2. 모순/교차 패턴을 추가했습니다.

- 성취 지표와 행동 지표가 상충하는 샘플을 규칙적으로 주입했습니다.
- 특정 변수 하나만으로 위험 라벨을 설명하기 어렵도록 설계했습니다.

3. 라벨 생성 규칙을 확률 기반으로 전환했습니다.

- 완전 규칙식 대신 sigmoid + random noise를 적용해 라벨 생성 불확실성을 반영했습니다.
- 동일 feature 조합에서도 라벨이 항상 같아지지 않도록 만들었습니다.

4. 시점 통합 스키마를 유지했습니다.

- 중간/기말 데이터를 동일 컬럼 구조로 유지하고, 시점 차이는 결측으로 표현했습니다.
- 결측값 자체를 정보로 활용하기 위해 후속 단계에서 결측 플래그 활용을 병행했습니다.

5. 검증 방식을 강화했습니다.

- 히스토그램과 요약 통계로 클래스 분포 겹침을 지속 점검했습니다.
- 다음 단계 계획으로 `N=1000~3000` 규모 확대와 `StratifiedKFold` 교차검증을 설정했습니다.

---

## 결과

1. 데이터 분포는 이전보다 현실적인 형태로 개선되었지만, 일부 실험에서 여전히 Logistic Regression `1.0` 고정 현상이 남아 있었습니다.
2. 이는 생성 규칙의 분리 신호가 아직 강하다는 의미로 해석되며, 단일 조치가 아닌 복합 개선이 필요하다는 결론을 확인했습니다.
3. 후속 작업 우선순위가 명확해졌습니다.

- 샘플 수 확대.
- 라벨 외생 요인 비중 확대.
- 클래스 비율 재조정.
- 교차검증 기반 안정성 점검.

4. "모델이 좋은가"보다 먼저 "데이터가 학습 가능한 난이도를 제공하는가"를 점검해야 한다는 기준이 정착되었습니다.

---

## 관련 파일

- `notebook/00_generate_dummy_dataset.ipynb`
- `notebook/_legacy_00_generate_dummy_dataset.ipynb`
- `notebook/02_risk_prediction.ipynb`
- `backend/scripts/train_model.py`
- `docs/issues_dummy_dataset_generation.md`

